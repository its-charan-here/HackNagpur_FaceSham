{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PyTorch version: 1.6.0\nCUDA version: 10.1\ncuDNN version: 7604\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "test_dir = \"test_videos/\"\n",
    "\n",
    "test_videos = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"])\n",
    "frame_h = 5\n",
    "frame_l = 5\n",
    "len(test_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['test_vid.mp4']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "test_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blazeface import BlazeFace\n",
    "facedet = BlazeFace().to(gpu)\n",
    "facedet.load_weights(\"weights/pytorch_blazeface/blazeface.pth\")\n",
    "facedet.load_anchors(\"weights/pytorch_blazeface/anchors.npy\")\n",
    "_ = facedet.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.read_video_1 import VideoReader\n",
    "from utils.face_extract_1 import FaceExtractor\n",
    "\n",
    "frames_per_video = 81 #frame_h * frame_l\n",
    "video_reader = VideoReader()\n",
    "video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n",
    "face_extractor = FaceExtractor(video_read_fn, facedet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "normalize_transform = Normalize(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isotropically_resize_image(img, size, resample=cv2.INTER_AREA):\n",
    "    h, w = img.shape[:2]\n",
    "    if w > h:\n",
    "        h = h * size // w\n",
    "        w = size\n",
    "    else:\n",
    "        w = w * size // h\n",
    "        h = size\n",
    "\n",
    "    resized = cv2.resize(img, (w, h), interpolation=resample)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def make_square_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "    size = max(h, w)\n",
    "    t = 0\n",
    "    b = size - h\n",
    "    l = 0\n",
    "    r = size - w\n",
    "    return cv2.copyMakeBorder(img, t, b, l, r, cv2.BORDER_CONSTANT, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MyResNeXt(models.resnet.ResNet):\n",
    "    def __init__(self, training=True):\n",
    "        super(MyResNeXt, self).__init__(block=models.resnet.Bottleneck,\n",
    "                                        layers=[3, 4, 6, 3], \n",
    "                                        groups=32, \n",
    "                                        width_per_group=4)\n",
    "        self.fc = nn.Linear(2048, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"weights/inference/resnext.pth\", map_location=gpu)\n",
    "\n",
    "model = MyResNeXt().to(gpu)\n",
    "model.load_state_dict(checkpoint)\n",
    "_ = model.eval()\n",
    "\n",
    "del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_video(video_path, batch_size):\n",
    "    try:\n",
    "        faces = face_extractor.process_video(video_path)\n",
    "        \n",
    "        face_extractor.keep_only_best_face(faces)\n",
    "        \n",
    "        if len(faces) > 0:\n",
    "            \n",
    "            x = np.zeros((batch_size, input_size, input_size, 3), dtype=np.uint8)\n",
    "\n",
    "            n = 0\n",
    "            for frame_data in faces:\n",
    "                for face in frame_data[\"faces\"]:     \n",
    "                    resized_face = isotropically_resize_image(face, input_size)\n",
    "                    resized_face = make_square_image(resized_face)\n",
    "\n",
    "                    if n < batch_size:\n",
    "                        x[n] = resized_face\n",
    "                        n += 1\n",
    "                    else:\n",
    "                        print(\"WARNING: have %d faces but batch size is %d\" % (n, batch_size))\n",
    "                    \n",
    "            if n > 0:\n",
    "                x = torch.tensor(x, device=gpu).float()\n",
    "\n",
    "                x = x.permute((0, 3, 1, 2))\n",
    "\n",
    "                for i in range(len(x)):\n",
    "                    x[i] = normalize_transform(x[i] / 255.)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(x)\n",
    "                    y_pred = torch.sigmoid(y_pred.squeeze())\n",
    "                    return y_pred[:n].mean().item()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Prediction error on video %s: %s\" % (video_path, str(e)))\n",
    "\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def predict_on_video_set(videos, num_workers):\n",
    "    def process_file(i):\n",
    "        filename = videos[i]\n",
    "        y_pred = predict_on_video(os.path.join(test_dir, filename), batch_size=frames_per_video)\n",
    "        return y_pred\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as ex:\n",
    "        predictions = ex.map(process_file, range(len(videos)))\n",
    "\n",
    "    return list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_on_video_set(test_videos, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.7821906805038452]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It is a DeepFake Video\n"
     ]
    }
   ],
   "source": [
    "if predictions[0] == 1:\n",
    "    val = \"error\"\n",
    "\n",
    "elif predictions[0] > 0.3:\n",
    "    val = \"It is a DeepFake Video\" \n",
    "else:\n",
    "    val = \"It looks Genuine\"\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}